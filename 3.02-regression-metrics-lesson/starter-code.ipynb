{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Regression Metrics\n",
    "\n",
    "_Authors: Matt Brems (DC), Dave Yerrington (SF), Riley Dallas (AUS)_\n",
    "\n",
    "\n",
    "> All models are wrong, but some are useful.\n",
    ">\n",
    "> -- <cite>George EP Box</cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "---\n",
    "\n",
    "Today's dataset (`Advertising.csv`) is from the [ISLR](http://www-bcf.usc.edu/~gareth/ISL/) website.\n",
    "\n",
    "Drop `\"Unnamed: 0\"` once you've loaded the CSV into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "---\n",
    "\n",
    "Run the following checks in the cells provided:\n",
    "\n",
    "- Are there any null values (`NaN`)?\n",
    "- Are there any corrupted columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types for any corrupted columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our feature matrix (`X`) and target vector (`y`)\n",
    "---\n",
    "\n",
    "The following columns will be our features:\n",
    "\n",
    "- `'TV'`\n",
    "- `'radio'`\n",
    "- `'newspaper'`\n",
    "\n",
    "The `sales` column is our label: the column we're trying to predict.\n",
    "\n",
    "In the cell below, create your `X` and `y` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model\n",
    "---\n",
    "\n",
    "In the cell below, create an instance of `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "---\n",
    "\n",
    "The `.fit()` method is how our model will learn the coefficients for each of the features (`'TV'`, `'radio'` and `'newspaper'`).\n",
    "\n",
    "Once it's fit, you can see the bias (aka intercept) and coefficients are by running:\n",
    "\n",
    "```python\n",
    "model.coef_\n",
    "model.intercept_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "---\n",
    "\n",
    "To get predictions from our model, all we have to do is run `.predict(X_to_predict)`. This will return a list (`np` array) of predictions, one for each row in our `X_to_predict`. Normally you'll use this method for making predictions on unseen data, but today we'll be evaluating the data that was fed into the model during `.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "---\n",
    "\n",
    "Recall the formula for linear regression:\n",
    "\n",
    "#### $ Y = \\beta_0 + \\beta_1 X_1 + \\varepsilon$\n",
    "\n",
    "It's important to remember that $\\varepsilon$ represents the irreducible error. Irreducible error is the error we'll never be able to solve. $\\varepsilon$ has a few important properties that we want our residuals to mimic:\n",
    "\n",
    "1. It is random (ie no discernible pattern)\n",
    "2. It has a mean of zero. Stated differently, our model should be just as likely to undershoot a prediction as it is to overshoot.\n",
    "\n",
    "In the cells below, do the following:\n",
    "\n",
    "1. Create your residuals: `y - y_hat`\n",
    "2. Calculate the mean of your residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals plot\n",
    "---\n",
    "\n",
    "We'll create a scatterplot to test for randomness. The `y` axis will be the residuals, and the `x` axis will be original `predictions`. \n",
    "\n",
    "In a residuals plot, we're looking for the following:\n",
    "\n",
    "- Scedasticity: We want a consistent variance between our low predictions and our high predictions (homoscedasticity). If you spot the opposite (heteroscedasticity) it means your target is not normally distributed. The remedy is to run your target vector through a power transformation (e.g. [Box-Cox or Yeo-Johnson](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html))\n",
    "- Outliers: If your loss function involves squaring the residuals (e.g. MSE, RMSE, R2), then outliers will have a lot of leverage over your model. One recommendation is to remove the worst offenders from your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.randn to show what we expect in a residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)\n",
    "---\n",
    "\n",
    "#### $MAE(\\mathbf{y},\\hat{\\mathbf{y}}) = \\frac{1}{n}\\sum_{i=1}^n(|y_i-\\hat{y}_i|)$\n",
    "\n",
    "Goal: Get MAE as close to 0 as possible.\n",
    "\n",
    "Pros: \n",
    "- Represents median distance from the predicted value.\n",
    "- In the original units of $Y$. \n",
    "- Is not heavily affected by outliers.\n",
    "\n",
    "Cons: \n",
    "- Depends on scale of $Y$. (i.e. housing prices vs. GPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuate MAE by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Sum of Squares (RSS)\n",
    "---\n",
    "\n",
    "#### $\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
    "\n",
    "RSS forms the basis for several loss/optimization functions that we'll cover next:\n",
    "\n",
    "- Mean squared error (MSE)\n",
    "- Root mean squared error (RMSE)\n",
    "- R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RSS by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)\n",
    "---\n",
    "\n",
    "#### $MSE(\\mathbf{y},\\hat{\\mathbf{y}}) = \\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$\n",
    "\n",
    "Goal: Get $MSE$ as close to 0 as possible.\n",
    "\n",
    "Pros: \n",
    "- Very common; part of other calculations.\n",
    "- Represents average distance squared from the predicted value.\n",
    "\n",
    "Cons: \n",
    "- Can be heavily affected by outliers.\n",
    "- Not in the original units of $Y$.\n",
    "- Depends on scale of $Y$. (i.e. housing prices vs. GPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE via sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)\n",
    "---\n",
    "\n",
    "#### $RMSE(\\mathbf{y},\\hat{\\mathbf{y}}) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$\n",
    "\n",
    "Goal: Get $RMSE$ as close to 0 as possible.\n",
    "\n",
    "Pros: \n",
    "- Pretty common; part of other calculations.\n",
    "- Represents (approximately) average distance from the predicted value.\n",
    "- In the original units of $Y$.\n",
    "\n",
    "Cons: \n",
    "- Can be heavily affected by outliers.\n",
    "- Depends on scale of $Y$. (i.e. housing prices vs. GPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Determination, $R^2$\n",
    "---\n",
    "\n",
    "#### $R^2 = \\frac{\\text{Explained variance}}{\\text{Total variance}} = 1 - \\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2}$\n",
    "\n",
    "Goal: Get $R^2$ as close to 1 as possible.\n",
    "\n",
    "> - score = 0: Model explains none of the variability of the response data around its mean.\n",
    "> - score = 1: Model explains all the variability of the response data around its mean.\n",
    "\n",
    "Pros:\n",
    "- Easy interpretation. \"An $R^2$ value of 0.8 means that 80% of the variability in the data are explained by our model, relative to a model with no predictors.\"\n",
    "- Common metric.\n",
    "- Does not depend on the scale of $Y$.\n",
    "- Works with more than just _linear_ regression.\n",
    "\n",
    "Cons:\n",
    "- As you add more variables, $R^2$ will never decrease (with linear regression). Adjusted R2 can handle this assumption better.\n",
    "\n",
    "> Are low $R^2$ scores bad?\n",
    ">\n",
    "> I'm glad you asked!  Not everything in regression is about getting the best predictions.  In some fields, such as human behavior, you would expect to achieve scores much lower then 50%!  For inference, perhaps .3 is enough to measure an effect then reported reliably!  Yes, there is more to machine learning than prediction.  Inference can be the goal as well!\n",
    "\n",
    "[Documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null sum of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 from model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
