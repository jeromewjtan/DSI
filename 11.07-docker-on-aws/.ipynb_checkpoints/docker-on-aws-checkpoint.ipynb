{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Docker on AWS\n",
    "\n",
    "_Authors: David Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Imagine, you're managing a new data science team that is tasked to build and deploy an application that predicts if someone will purchase products depending on what and how they browse products from a mobile app.  Your team however, consists of **data scientists** and **a machine learning engineer** with the following platforms:\n",
    "\n",
    "![](https://snag.gy/0LJAqb.jpg)\n",
    "\n",
    "- 3 data scientists using Windows\n",
    "- 5 data scientists using Mac \n",
    "- 1 machine learning engineer using Linux\n",
    "- CTO uses Raspberry Pi\n",
    "\n",
    "Everone has a different role on the team, however, will be using the same development environment on a single computer, contributing to a _private_ github repo:\n",
    "\n",
    "![](https://snag.gy/R35WZQ.jpg)\n",
    "\n",
    "- Jupyter Notebook / Lab\n",
    "- Python + PySpark\n",
    "- Scala + Spark\n",
    "- Postgres Database\n",
    "\n",
    "As a team, you will build a predictive model that will be deployed in a backend system that will run from EC2 on AWS.  Everyone will run the same environment so they can develop and test how their work interacts with all aspects of their product, across their team.\n",
    "\n",
    "### What are some challenges to set everyone up with the same development environment? (thread)\n",
    "\n",
    "Additional consideration:  How do we run the app in production in AWS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker:  Overview\n",
    "\n",
    "<img src=\"https://snag.gy/n9LA0C.jpg\">\n",
    "\n",
    "## But wait, there's more:  Docker Hub\n",
    "\n",
    "<img src=\"https://snag.gy/qXZJ5S.jpg\">\n",
    "\n",
    "\n",
    "### Popular Docker Hub Image / Containers\n",
    "- [MySQL](https://hub.docker.com/_/mysql/)\n",
    "- [PostgreSQL](https://hub.docker.com/_/postgres/)\n",
    "- [Django](https://hub.docker.com/_/django/)\n",
    "- [Flask](https://hub.docker.com/r/jazzdd/alpine-flask/)\n",
    "\n",
    "These are only a few that are relevant to what we might find useful in class, but it's fairly easy to build a Docker container paired with an image, then share it with the community using [Docker Hub](https://hub.docker.com/).\n",
    "\n",
    "**Jupyter Notebook Flavors**\n",
    "\n",
    "The fine people at Jupyter maintain a somewhat comprehensive collection of Docker containers that range from barebones, to completely loaded.  Of interest, is a notebook stack that runs scala, R, Python, Spark, and even Keras and Tensorflow that work with GPU hardware that can be provisioned with minimal effort on an EC2 instance.\n",
    "\n",
    "![](https://snag.gy/SKmWxA.jpg)\n",
    "\n",
    "> To contribute your own custom Docker conainer (which we haven't explained how to do) is not a bad thing to add to your resume.  Jupyter has laid out a [nice guide](http://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html) for you to learn how.\n",
    "\n",
    "- jupyter/base-notebook\n",
    "- jupyter/minimal-notebook\n",
    "- jupyter/scipy-notebook\n",
    "- jupyter/r-notebook \n",
    "- jupyter/tensorflow-notebook\n",
    "- jupyter/datascience-notebook\n",
    "- jupyter/pyspark-notebook\n",
    "- jupyter/all-spark-notebook\n",
    "\n",
    "Full list of notebooks are available from the [Jupyter Docker Hub page](https://hub.docker.com/u/jupyter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you can do with Docker\n",
    "\n",
    "- Setup a convolutional neural network with GPU hardware (very fast epochs!)\n",
    "- Run a variety of Jupyter notebook configurations\n",
    "- Run the exact same application on any platform\n",
    "- Quickly boot up any infrastruture on Win / Linux / Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Install on AWS EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubuntu LTS \n",
    "Login to your EC2 instance and pipe the remote script to a shell using this `curl` command:\n",
    "\n",
    "```bash\n",
    "curl -sSL https://get.docker.com | sh\n",
    "```\n",
    "\n",
    "Then after you've installed Docker on your Ubuntu Linux system, the install script will instruct you to add the `ubuntu` user to the `docker` group:\n",
    "\n",
    "```bash\n",
    "sudo usermod -aG docker ubuntu\n",
    "```\n",
    "\n",
    "After you add your `ubuntu` user to group `docker`, simply exit and re-login.\n",
    "\n",
    "```bash\n",
    "exit\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Linux\n",
    "Login to your EC2 instance and use the \"yum\" package manage to install Docker:\n",
    "\n",
    "```bash\n",
    "sudo yum update -y\n",
    "sudo yum install docker\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image vs Container\n",
    "\n",
    "Compared to standard virtual machines, Docker while also using a virtual machine infracture, differs in that it abstracts running states between what is known as an **image** and a **conatiner**.\n",
    "\n",
    "You might say an **image** is a virtual machine instance, and a **container** is simply an execution environment that uses an **image** with a preset definition of instructions.\n",
    "\n",
    "A more technically accurate definition is that Docker **images** are snapshops of **containers** and can be built, extended, and customized for any purpose.\n",
    "\n",
    "It might be helpful to consider this order of operations for a Docker system:\n",
    "\n",
    "- Docker engine builds an image with Ubuntu Linux\n",
    "- A read-write filesystem is added on top\n",
    "- Resources are initialized from settings definition\n",
    "  - IP address\n",
    "  - Firewall rules\n",
    "  - Open ports / port forwards\n",
    "  - Resource limits with CPU and memory\n",
    "- If a conatiner is defined to \"run\", a process will initialize inside the image\n",
    "\n",
    "> _A container can be stopped and restarted, in which case it will retain all settings and filesystem changes but will lose anything in memory and all processes will be restarted. For this reason a stopped or exited container is not the same as an image._\n",
    "\n",
    "## Example:  How do you build a Docker container?\n",
    "\n",
    "Docker containers can be built using a **Dockerfile**.  At the core of Docker, is the **Dockerfile** which is a definition of resouces and commands that provision and can be executed.\n",
    "\n",
    "Here's an example of a **Dockerfile** that runs a **Flask** Python service:\n",
    "\n",
    "```bash\n",
    "FROM python:3\n",
    "\n",
    "RUN mkdir src\n",
    "WORKDIR /src\n",
    "COPY . /src\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "ARG SERVICE_FILE=service.py\n",
    "\n",
    "ENV FLASK_APP=$SERVICE_FILE\n",
    "ENV FLASK_DEBUG=1\n",
    "\n",
    "ENTRYPOINT [\"python\", \"-m\", \"flask\", \"run\", \"--host\", \"0.0.0.0\"]\n",
    "```\n",
    "\n",
    "- `FROM` creates a layer from the `python:3` Docker image.\n",
    "- `COPY` adds files from your Docker clientâ€™s current directory to the container.\n",
    "- `RUN` installs Python packages on the conatiner with `pip`.\n",
    "- `EXPOSE` opens port 5000.\n",
    "- `ARG` allows you to start the Docker container to run a different file other than `service.py` but defaulting to `service.py`.\n",
    "- `ENV` sets environmental variables on container.\n",
    "- `ENTRYPOINT` specifies a command that will run persistently within the container.\n",
    "\n",
    "If we wanted to build this container, we would only need to do this 1x:\n",
    "```bash\n",
    "docker build --rm -t flask-dsi-plus .\n",
    "```\n",
    "\n",
    "Then to run this container:\n",
    "\n",
    "```bash\n",
    "docker run -it -p 5000:5000 -v `pwd`:/src --rm flask-dsi-plus\n",
    "```\n",
    "\n",
    "> This would load the file `service.py`, from the current directory, into the container.  Then we could simply edit the file and the Flask app on the container would reload itself upon new edits.\n",
    "\n",
    "To read more about this specific example and how to run it:\n",
    "- <a href=\"https://git.generalassemb.ly/DSI-US-4/course-info/wiki/Web-Service-Implementation-Guide-(Flask)\">Web Service Implementation Guide (Flask)</a>\n",
    "- [DSI: Flask Docker Repo](https://git.generalassemb.ly/DSI-US-4/flask-docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running basic Jupyter + Python in 1 shell command\n",
    "\n",
    "To get a basic notebook running, using the \"scipy-notebook\" container from \"jupyter\"'s repo.\n",
    "\n",
    "```bash\n",
    "docker run -p 8888:8888 jupyter/scipy-notebook\n",
    "```\n",
    "\n",
    "This will download the image/conatainer that is preconfigured with pandas, scipy, scikit-learn, jupyter notebook, and the most common scientific Python libraries configured for data science.\n",
    "\n",
    "**Accessing your Notebook**\n",
    "\n",
    "To access the notebook, you simply need to copy the token from the console, and SSH tunnel **from your local machine** to **your EC2 instance running the `scipy-notebook` container with Docker**, forwarding a port:\n",
    "\n",
    "**Ubuntu Users**\n",
    "```bash\n",
    "ssh -L 9999:localhost:8888 ubuntu@[public-dns from your EC2 dashboard]\n",
    "```\n",
    "\n",
    "**Amazon Linux Users**\n",
    "```bash\n",
    "ssh -L 9999:localhost:8888 ec2-user@[public-dns from your EC2 dashboard]\n",
    "```\n",
    "\n",
    "> **Troubleshooting**\n",
    "> \n",
    "> There will likely be a few people who will have problems with this.\n",
    ">\n",
    "> - If you have a problem with connecting to your EC2 instance, you might double check that your SSH key is setup properly.  Check the guide and consider setting up a new EC2 instance.\n",
    ">\n",
    ">\n",
    "> - If you've run out of disk space, consider booting up a new EC2 instance configured with more storage.  If you plan on using your EC2 instance for more than a few days, consider adding at least 20G of disk storage to it.\n",
    "\n",
    "If you've started your Dockerized notebook instance and tunneled using the above method, you should be able to access your notebook running on the remote EC2 instance by visiting this address:\n",
    "\n",
    "http://localhost:9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mounting a Local Volume\n",
    "\n",
    "The most common use case for interacting with files on a Docker conatiner is the mount them from your EC2 filesystem to your Docker containers filesystem.\n",
    "\n",
    "By adding ```-v `pwd`:/home/jovyan``` to run our Docker `scipy-notebook` containers, anything in the current working directory `pwd`, will be mounted inside the containers filesystem @ `/home/jovyan` which is where the notebook runs from.  **This allows any file to be accessed from our host OS to the containers filesystem.**\n",
    "\n",
    "Stop your current Jupyter container by hitting `ctrl-c`.  Then start it again, mounting the current directory to the containers filesystem (at: `/home/jovyan`):\n",
    "\n",
    "```bash\n",
    "docker run -p 8888:8888 -v `pwd`:/home/jovyan jupyter/scipy-notebook\n",
    "```\n",
    "\n",
    "Now whenver we create a new notebook, our notebook files will be accessible from our host system running the Docker container, rather than the container itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc Helpful Commands\n",
    "\n",
    "```bash\n",
    "# Show CPU, file and network I/O stats in real-time\n",
    "docker stats\n",
    "\n",
    "# Show running containers\n",
    "docker ps\n",
    "\n",
    "# Login as root into a running container\n",
    "docker exec -it <container name or id> /bin/bash\n",
    "\n",
    "# Show running and stopped containers\n",
    "docker ps -a\n",
    "\n",
    "# Show Docker images\n",
    "docker images\n",
    "\n",
    "# Remove a Docker image\n",
    "docker rmi [image id]\n",
    "```\n",
    "\n",
    "An excellent cheatsheet:\n",
    "https://gist.github.com/garystafford/f0bd5f696399d4d7df0f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, persist a process with `tmux`\n",
    "\n",
    "While not exclusive to Docker, it's helpful to be able to run a process remotely, then have it persist beyond the lifetime of your session.  So imagine your working from your EC2 notebook, then you close your laptop, your secure shell session will time out eventually, then your notebook will stop running.  You can prevent that with shell persistance with `tmux`.\n",
    "\n",
    "Start a new named `tmux` session:\n",
    "\n",
    "```bash\n",
    "tmux new -s notebook\n",
    "\n",
    "```\n",
    "\n",
    "Whenever you want to come back to your session, even after completely logging out of your EC2 machine, simply:\n",
    "\n",
    "```bash\n",
    "tmux attach -t notebook\n",
    "```\n",
    "\n",
    "There are a ton of cool features with `tmux` and you can learn more about them here:\n",
    "\n",
    "**Cheatsheets**\n",
    "- https://gist.github.com/michaellihs/b6d46fa460fa5e429ea7ee5ff8794b96\n",
    "- http://atkinsam.com/documents/tmux.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
