# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Trees-CARTs

---

## Materials We Provide


| Topic | Description | Link |
| --- | --- | --- |
| Lesson | Starter Code | [Link](./starter-code.ipynb)

> Data: Titanic Data

---

## Learning Objectives

*After this lesson, students will be able to:*

- Understand the intuition behind decision trees.
- Calculate Gini and entropy.
- Describe how decision trees use gini and entropy to make decisions.
- Fit, generate predictions from, and evaluate decision tree models.
- Interpret and tune `max_depth`, `min_samples_split`, `min_samples_leaf`.

---

## OPTIONAL: Resources for Practice and Learning

- [Documentation for `DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
- [Documentation for `DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)
- [`sklearn.tree` module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree)
- [Good discussion of interpretability vs. prediction as we dive into various methods](https://towardsdatascience.com/machine-learning-interpretability-techniques-662c723454f3)
- [Supplemental Code including GraphViz visualization](./supplemental/classification-and-regression-trees.ipynb)