{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Lesson: A/B Testing\n",
    "\n",
    "Our goal is often to learn about a population (usually how the population behaves or why it behaves the way it does.)\n",
    "\n",
    "**Inferential statistics** focuses on generalizing results from a sample to a larger **population of interest**.\n",
    "- Because we can't study populations directly, we have to take subsets of these populations called **samples**.\n",
    "- We calculate some value on a sample, called a **statistic**.\n",
    "- We make inferences about our **parameters** so that we learn about our **population**.\n",
    "\n",
    "<details><summary>What is a parameter?</summary>\n",
    "A parameter is a number that describes a population.\n",
    "</details>\n",
    " \n",
    "When attempting to learn about these parameters, there are two main types of questions we ask:\n",
    "- Is this a valid value for my parameter?\n",
    "- What is a range of likely values for my parameter?\n",
    "\n",
    "We'll refresh our memories on what Frequentist confidence intervals and hypothesis tests are and show the \"Bayesian versions\" of these. Remember that our goal in Bayesian inference is to always find the posterior distribution... this is because \"everything we need to know about a parameter can be found in its posterior [distribution]!\" (Quote taken from [this site](https://newonlinecourses.science.psu.edu/stat414/node/241/).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher: (Frequentist) Confidence Interval\n",
    "**Summary**: **A confidence interval describes a set of likely values for the parameter based on a statistic.** Confidence intervals will be centered at our \"best guess\" and then include a margin of error. \n",
    "- The technical term for this \"best guess\" is a **point estimate**.\n",
    "- The technical term for the margin of error is called our **standard error**, or the standard deviation of a statistic, multiplied by a **multiplier**.\n",
    "\n",
    "**Structure**: $$[\\text{point estimate}] \\pm [\\text{multiplier}]\\times[\\text{standard error}]$$\n",
    "\n",
    "**Example**: A 95% confidence interval for the average hours of sleep DSI students get each night is (5.5,7.5). We interpret this by saying that we are 95% confident that the average amount of sleep DSI students get each night is between 5.5 hours and 7.5 hours.\n",
    "\n",
    "General formulation:\n",
    "> We are 95% confident that the true $\\theta$ is between $A$ and $B$.\n",
    "\n",
    "### Bayesian Credible Interval\n",
    "**Summary**: **A credible interval describes a set of likely values for the parameter based on a statistic.**\n",
    "\n",
    "**Structure**: A credible interval is almost always based on the highest density interval of the posterior distribution. In the image below, our credible interval for each parameter is the interval that covers the 95% \"likeliest\" area of the posterior distribution.\n",
    "\n",
    "<img src=\"./images/HPD.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "**Example**: The 95% credible interval for the parameter above is 2.49 to 24.8. We interpret this by saying that there is a 95% chance that the parameter is between 2.49 and 24.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher: (Frequentist) Hypothesis Test\n",
    "**Summary**: We are going to come up with two hypotheses, called the **null hypothesis** and **alternative hypotheses**. We'll assume the null hypothesis is true, then gather evidence and measure how likely the null hypothesis is to be true.\n",
    "\n",
    "$ H_0: \\text{Boring thing I want to prove wrong} $\n",
    "\n",
    "$ H_A: \\text{Interesting thing I want to prove right} $\n",
    "\n",
    "- If there's a lot of evidence (READ: data) to suggest that the null hypothesis is false, we'll say that the null hypothesis is false, meaning we accept the alternative hypothesis to be true.\n",
    "- If there's not a lot of evidence to suggest that the null hypothesis is false, we'll say that we can't accept that the null hypothesis is false.\n",
    "\n",
    "**Structure**: \n",
    "1. Construct a null hypothesis that you seek to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your point estimate.\n",
    "4. Calculate your test statistic - this quantifies how far our observed results are from our expected results.\n",
    "5. Find your $p$-value and make a conclusion.\n",
    "\n",
    "### Bayesian Estimation\n",
    "**Summary**: Bayesian estimation allows us to use the posterior distribution to determine whether a value is or isn't reasonable for the parameter.\n",
    "\n",
    "<img src=\"./images/HPD.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "**Example**: We want to determine whether or not each parameter above is credibly different from zero. In this case, (assuming we were comfortable with 95% as our \"highest posterior density\" region), we would accept that 0 is a reasonable choice for our first parameter and accept that 0 is not a reasonable value for our second parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist vs. Bayesian\n",
    "\n",
    "Frequentist:\n",
    "- Pro: More people are familiar with this.\n",
    "- Pro: Seems to be more objective (but often isn't)!\n",
    "- Con: Counter-intuitive interpretation.\n",
    "- Con: Process is complicated! (Identify hypotheses, choose a test, make sure all assumptions are met, calculate statistic/error, interpret.)\n",
    "\n",
    "Bayesian:\n",
    "- Pro: Straightforward process. (Pick a prior, pick a likelihood, interpret posterior.)\n",
    "- Pro: More straightforward interpretation.\n",
    "- Con: Less widely understood.\n",
    "- Con: Usually need more computing power.\n",
    "- Con: Seems to be more subjective (but often isn't)!\n",
    "\n",
    "There are pros and cons to taking Frequentist approaches versus Bayesian approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Experimental Design / A/B Testing\n",
    "\n",
    "**A/B Testing** is a term for a randomized experiment with two variants: A and B. We often use \"experiment\" and \"A/B testing\" interchangably, but A/B testing is a term of art that is used mainly to describe cases where we only test two groups.\n",
    "\n",
    "<details><summary> Why would we conduct a randomized experiment or an A/B test?\n",
    "</summary>\n",
    "\n",
    "- Experiments allow us to establish causation, whereas no other methods yet exist for establishing a causal relationship.\n",
    "</details>\n",
    "\n",
    "Experiments are the preferred way of making conclusions, as observational studies or surveys may not give us the level of certainty we might attain with experiments.\n",
    "\n",
    "#### 2008 Obama Campaign\n",
    "\n",
    "The Obama campaign leveraged an experiment in order to get more email addresses.\n",
    "\n",
    "![](./images/obama_media_button.png)\n",
    "\n",
    "The campaign examined six different types of \"media\" and four different \"buttons\" on their page for 26 different combinations media and button. They wanted to see which did the best job at getting people to share their email addresses.\n",
    "\n",
    "<details><summary>Already, we know what the parameter is. What is it?</summary>\n",
    "The Obama campaign wanted to increase the number of email addresses. The parameter they wanted to study was the percentage of people who gave their email addresses for each media/button combination. They'll pick the combination of media and button that has the best performance!\n",
    "</details>\n",
    "\n",
    "This experiment was wildly successful. By running this experiment, the Obama campaign increased the number of email addresses by 40% (from 7.1 million to about 10 million). Since each email donated 21 dollars on average, they believe this experiment netted them an additional 60,000,000 dollars. You can (*should*) read more [here](https://blog.optimizely.com/2010/11/29/how-obama-raised-60-million-by-running-a-simple-experiment/)!\n",
    "\n",
    "![](./images/obama_winner.png)\n",
    "\n",
    "When designing an experiment, there are a few best practices to keep in mind.\n",
    "1. Define your parameter of interest before the experiment. (This is also commonly known as your dependent variable.)\n",
    "<details><summary>Why?</summary>\n",
    "If we don't do this, then we can change the goals of our experiment in the middle of the experiment. By changing your goal mid-analysis, you're very close to measuring a bunch of different things, then saying \"oh this thing happened to have a significant difference so let's make this our goal!\" It's like $p$-hacking, where you're running a bunch of hypothesis tests to see which test will give you a significant $p$-value.\n",
    "</details>\n",
    "\n",
    "2. Only one variable should generally be changed at a time.\n",
    "<details><summary>Why?</summary>\n",
    "If you're changing multiple independent variables, it gets harder to assign causality to a single variable. If I changed the media and button on my website, I don't really know if my boost in emails is due to the media or due to the button. (There are types of experiment designs, like factorial designs, that can account for having multiple changed variables.)\n",
    "</details>\n",
    "\n",
    "3. Identify your observational units.\n",
    "<details><summary>Why?</summary>\n",
    "This is good for all data science projects. What does each \"row\" in our dataframe mean? Is it a person? Is it a county? Is it a state? Is it a point in time?\n",
    "</details>\n",
    "\n",
    "4. [Block](https://stattrek.com/statistics/dictionary.aspx?definition=randomized%20block%20design) your observations so that each group has the same distribution of important variables. For example, make sure that when you split web traffic into groups, one group doesn't have an overly large share of a certain demographic. (We commonly also use the word \"stratify\" to mean the same thing.)\n",
    "<details><summary>Why?</summary>\n",
    "If the people assigned to group A and the people assigned to group B look very different on variables that matter (like age or socioeconomic status), then we can't know if our experimental results are caused by treatment A/B or caused by other variables.\n",
    "</details>\n",
    "\n",
    "5. Randomly assign observations to groups.\n",
    "<details><summary>Why?</summary>\n",
    "No matter how many variables we block on, there are going to be some things that we just can't control for. By randomly assigning individuals to groups, we expect that all of those things we can't control for will balance out among our groups.\n",
    "</details>\n",
    "\n",
    "6. Make sure there is a control (baseline) group!\n",
    "<details><summary>Why?</summary>\n",
    "It isn't enough to say \"look at how many emails we got from this group!\" We need to compare our results to some baseline group.\n",
    "</details>\n",
    "\n",
    "Suppose that you've recently been hired as a data scientist to work for IKEA. Your job is to identify how the store should be organized. There is the current layout of the store (layout 1) and two other proposed layouts (layouts 2 and 3).\n",
    "- What might be your parameter of interest? (Be creative!)\n",
    "- What one variable would we change?\n",
    "- Identify the observational units.\n",
    "- How might you try to block/stratify these observational units?\n",
    "- What is your control/baseline group?\n",
    "\n",
    "<details><summary> What are situations where we would not conduct an experiment or an A/B test? </summary>\n",
    "\n",
    "- Scenarios in which it is unethical to conduct an experiment.\n",
    "- Cases where experiments are too expensive or time-consuming.\n",
    "</details>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Experimental Results\n",
    "\n",
    "Depending on how we set up our experiment, there will be a specific way to analyze the data.\n",
    "- One-Sample $t$-test\n",
    "- Two-Sample $t$-test\n",
    "- Matched Pairs $t$-test\n",
    "- ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with Walmart store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/df.jpg_large\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Sample $t$-test\n",
    "A **one-sample $t$-test** is a way for us to compare one parameter to a fixed number.\n",
    "\n",
    "$H_0: \\mu_B = 120000$\n",
    "\n",
    "$H_A: \\mu_B \\neq 120000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Type'] == 'B', 'Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Suppose my significance level $\\alpha$ is 0.05. What is my conclusion here?</summary>\n",
    "Because $p < \\alpha$, I reject $H_0$. Since $H_0$ has been rejected, I accept that the average size for group B is not 120,000.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Sample $t$-test\n",
    "When doing experiments, we're more likely to want to compare results from two groups instead of comparing one group to a number. This is where a **two-sample $t$-test** comes into play. \n",
    "\n",
    "Suppose that we had randomly split the Walmart stores into groups A and B, gave coupons to people walking in the door at Walmarts in group A, and examined the difference.\n",
    "\n",
    "In this case, we want to examine $\\mu_A - \\mu_B$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "H_0: \\mu_A = \\mu_B &\\Rightarrow& \\mu_A - \\mu_B = 0 \\\\\n",
    "H_A: \\mu_A \\ne \\mu_B &\\Rightarrow& \\mu_A - \\mu_B \\ne 0\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Let's check out the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind) for a two-sample $t$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Suppose we established our significance level to be $\\alpha = 0.05$. How would I interpret the results of this hypothesis test?\n",
    "</summary>\n",
    "Because $p < \\alpha$, I reject $H_0$. Since $H_0$ has been rejected, $H_A$ must be true. Therefore, I accept that the average size for groups A and B are different.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matched Pairs $t$-test\n",
    "From the documentation for the two-sample $t$-test, it was very clear that the two samples needed to be **independent** of one another. That is, changes in one group should not affect the other group.\n",
    "\n",
    "However, this isn't always the case. Suppose we've developed a drug that helps to reduce the systolic blood pressure of individuals. \n",
    "- We recruit 10 individuals to participate in our study.\n",
    "- We measure all 10 patients' systolic blood pressure.\n",
    "- We administer the drug to all 10 patients over the course of eight weeks.\n",
    "- We measure all 10 patients' systolic blood pressure again.\n",
    "\n",
    "In this case, we want to compare the **pre-**drug values against the **post-**drug values to see if our drug had the intended effect. Here, our pre-drug values and post-drug values are certainly not independent of one another - we're taking our measurements on the same people!\n",
    "\n",
    "This is where the **matched pairs $t$-test** comes into play. The matched pairs t-test is a way for us to take two dependent samples and compare their means. (Spoiler alert: it just takes sample 2, subtracts sample 1, and conducts a one-sample $t$-test on the difference.)\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "H_0: \\mu_{pre} &=& \\mu_{post} \\\\\n",
    "H_A: \\mu_{pre} &\\ne& \\mu_{post}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "Let's check out the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) for a matched pairs $t$-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systolic_pre = np.array([130,135,139,153,130,142,136,128,144,155])\n",
    "systolic_post = np.array([125,134,140,151,160,140,138,124,141,148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Suppose we established our significance level to be $\\alpha = 0.05$. How would I interpret the results of this hypothesis test?\n",
    "</summary>\n",
    "Because $p > \\alpha$, I fail to reject $H_0$. I cannot accept that either $H_0$ or $H_A$ are true.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA\n",
    "Jumping back to the Walmart example, suppose we want to compare all three groups.\n",
    "> Another example: Suppose you're a data scientist for a factory and you have three assembly lines running. You want to identify if the lines are all performing at roughly the same level, or if at least one line is slower than the others.\n",
    "\n",
    "In this case, we can't run a one-sample or a two-sample test... so we need to use ANOVA, or \"Analysis of Variance,\" which will allow us to compare **more than two independent** samples.\n",
    "\n",
    "Despite its name, ANOVA is a type of hypothesis test that will test whether or not all samples have the same mean.\n",
    "\n",
    "In this case, the hypotheses are:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "&H_0: &\\mu_A = \\mu_B = \\mu_C = \\ldots \\\\\n",
    "&H_A:& \\text{at least one } \\mu_i \\ne \\mu_j\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Let's check out the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html) for ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>\n",
    "Suppose we established our significance level to be $\\alpha = 0.05$. How would I interpret the results of this hypothesis test?\n",
    "</summary>\n",
    "\n",
    "- Because $p < \\alpha$, we reject the null hypothesis and accept that at least one mean is different from the other means.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Estimation (BONUS)\n",
    "\n",
    "Our goal here is to study a parameter of interest. This is a natural place for Bayesian estimation to come into play.\n",
    "\n",
    "- In short, I'm going to find a posterior distribution for the mean of the pre-test group, a posterior distribution for the mean of the post-test group, then compare the two distributions!\n",
    "\n",
    "[We've linked a notebook walking through how PyMC3 is used](https://docs.pymc.io/notebooks/BEST.html) for an experiment. You can also check out the journal article arguing that Bayesian estimation is superior to frequentist $t$-testing [here](http://www.indiana.edu/~kruschke/BEST/BEST.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = pd.DataFrame({\n",
    "    'systolic_pre':systolic_pre,\n",
    "    'systolic_post':systolic_post\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyMC3\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y_{pre} &\\sim& N(\\mu_{pre}, \\sigma_{pre}) \\\\\n",
    "Y_{post} &\\sim& N(\\mu_{post}, \\sigma_{post}) \\\\\n",
    "\\mu_{pre} &\\sim& N(140, 15) \\\\\n",
    "\\mu_{post} &\\sim& N(140, 15) \\\\\n",
    "\\sigma_{pre} &\\sim& Uniform(0, 10) \\\\\n",
    "\\sigma_{post} &\\sim& Uniform(0, 10) \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select the same prior for both groups.\n",
    "\n",
    "<details><summary>Why would I pick the same prior for the \"pre\" group and the \"post\" group?</summary>\n",
    "- In an experiment, I'm trying to determine if the two groups have similar values for the parameter of interest. If I pick different priors for the two groups, I'm basically skewing my results out of the gate!\n",
    "</details>\n",
    "\n",
    "For my priors, I'll say that both groups are Normally distributed with a mean of 140 and a standard deviation of 15. (This might be informed by prior research on systolic blood pressures among people who have high blood pressure.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set priors.\n",
    "with pm.Model() as model:\n",
    "    pre_mean = pm.Normal('pre_mean', mu = 140, sd = 15)\n",
    "    post_mean = pm.Normal('post_mean', mu = 140, sd = 15)\n",
    "    pre_sd = pm.Uniform('pre_sd', lower = 0.5, upper = 10)\n",
    "    post_sd = pm.Uniform('post_sd', lower = 0.5, upper = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pre_observed = pm.Normal(\n",
    "        'pre_observed',\n",
    "        mu=pre_mean,\n",
    "        sd=pre_sd,\n",
    "        observed=drug['systolic_pre']\n",
    "    )\n",
    "    \n",
    "    post_observed = pm.Normal(\n",
    "        'post_observed',\n",
    "        mu=post_mean,\n",
    "        sd=post_sd,\n",
    "        observed=drug['systolic_post']\n",
    "    )\n",
    "    mean_diff = pm.Deterministic('mean_diff', pre_mean - post_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, color='#87ceeb');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
