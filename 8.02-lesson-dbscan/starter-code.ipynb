{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# DBSCAN\n",
    "\n",
    "_Authors: Matt Brems (DC), Riley Dallas (AUS)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where `DBSCAN` shines\n",
    "---\n",
    "\n",
    "`DBSCAN` does really well when there is clear \"separation\" within your dataset. `load_iris` is a good example of this, because one of the species is an island unto itself.\n",
    "\n",
    "**In the cell below, load the iris dataset into a `pandas` DataFrame. Ignore the species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: `StandardScaler`\n",
    "---\n",
    "\n",
    "Because clustering models are based on distance, we don't want the magnitude of our features to affect the algorithm. Therefore, when clustering **you should always scale your data**.\n",
    "\n",
    "Create `X_scaled` using an instance of `StandardScaler` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DBSCAN`\n",
    "---\n",
    "\n",
    "Fit an instance of `DBSCAN` to `X_Scaled`. Use the default parameters for now (we'll tune them in a minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Silhouette score\n",
    "---\n",
    "\n",
    "Recall the formula for Silhouette score:\n",
    "\n",
    "### $s_i = \\frac{b_i - a_i}{max\\{a_i, b_i\\}}$\n",
    "\n",
    "Where:\n",
    "- $a_i$ = Cohesion: Average distance of points within clusters\n",
    "- $b_i$ = Separation: Average distance from point $x_i$ to all points in the next nearest cluster.\n",
    "\n",
    "In the cell below, use the `silhouette_score` function from `sklearn` to evaluate our `DBSCAN` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: `pairplot`\n",
    "---\n",
    "\n",
    "Now let's view our clusters using `seaborn`'s `pairplot` method. \n",
    "\n",
    "1. First, you'll need to assign the clusters (`dbscan.labels_`) to your original DataFrame.\n",
    "2. Then you'll create a `pairplot` using the `cluster` column as the hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where `DBSCAN` does poorly\n",
    "---\n",
    "\n",
    "`DBSCAN` is dependent on two things:\n",
    "\n",
    "1. Consistent density (one `eps` to rule them all)\n",
    "2. Clear separation of the clusters within your dataset\n",
    "\n",
    "The `load_wine` dataset is more or less clumped together, which makes it a great dataset for exposing one of the weaknesses of `DBSCAN`: no clear separation.\n",
    "\n",
    "In the cell below, load the wine dataset into a `pandas` DataFrame. Ignore the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: `StandardScaler`\n",
    "---\n",
    "\n",
    "Because clustering models are based on distance, we don't want the magnitude of our features to affect the algorithm. Therefore, when clustering **you should always scale your data**.\n",
    "\n",
    "Create `X_scaled` using an instance of `StandardScaler` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DBSCAN`\n",
    "---\n",
    "\n",
    "Fit an instance of `DBSCAN` to `X_Scaled`. Finding the right values for `eps` and `min_samples` can take a while, so to save on time we'll use the following parameters:\n",
    "\n",
    "- 2.3 for `eps`\n",
    "- 4 for `min_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "---\n",
    "\n",
    "Calculate the silhouette score for our instance of `DBSCAN` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "---\n",
    "\n",
    "It's not practical to create a `pairplot` because the wine dataset has several features. We'll try some different techniques in a bit.\n",
    "\n",
    "In the cell below, create a `cluster` column using `dbscan.labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring each cluster\n",
    "---\n",
    "\n",
    "Clustering is sort of backwards: We fit a model, **then** we do EDA on each cluster. You can go one of two routes:\n",
    "\n",
    "1. Break each cluster into its own DataFrame\n",
    "2. Use `.groupby()` extensively\n",
    "\n",
    "In the cell below, use `.groupby()` in conjunction with `.mean()` and see if you spot any defining characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
