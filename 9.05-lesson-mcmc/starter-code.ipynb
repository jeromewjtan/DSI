{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Markov Chain Monte Carlo Methods\n",
    "\n",
    "> Author: Matt Brems\n",
    "\n",
    "### LEARNING OBJECTIVES\n",
    "By the end of this lesson, students should be able to:\n",
    "- Identify the Markov property.\n",
    "- Describe Monte Carlo simulations.\n",
    "- Describe how MCMC works.\n",
    "- Identify situations where MCMC is beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "### Framing: What should you get out of this lecture?\n",
    "- Markov Chains and Monte Carlo methods (separately) are important tools in many settings. These are terms with which you want to be familiar, as this won't be the last time that you see them.\n",
    "- When asked about MCMC, there are three answers you can give.\n",
    "    - **Basic**: MCMC allows us to leverage computers to do Bayesian statistics.\n",
    "    - **Intermediate**: MCMC is a method that can find the posterior distribution of our parameter of interest. Specifically, this type of algorithm generates Monte Carlo simulations in a way that relies on the Markov property, then accepts these simulations at a certain rate to get the posterior distribution.\n",
    "    - **Advanced**: The full-blown lecture.\n",
    "    \n",
    "Our goal is to get you to that intermediate stage today.\n",
    "\n",
    "---\n",
    "\n",
    "### OPENING: Bayes' Theorem\n",
    "\n",
    "$$ f(\\theta|y) = \\frac{f(y|\\theta)f(\\theta)}{f(y)} \\propto f(y|\\theta)f(\\theta)$$\n",
    "\n",
    "- $f(\\theta)$: prior distribution of the parameter of interest.\n",
    "- $f(y|\\theta)$: likelihood function of your data given all possible values of the parameter.\n",
    "- $f(\\theta|y)$: posterior distribution of the parameter of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Our goal is to always find the posterior distribution. Why would we want that?</summary>\n",
    "- The posterior distribution is a complete summary of $\\theta$ after taking our data/evidence into account.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is conjugacy?</summary>\n",
    "\n",
    "- Conjugacy is where our prior and our posterior follow the same parametric form.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What happens when we don't have conjugacy?</summary>\n",
    "\n",
    "- Before computers, we had to pick priors or likelihoods that \"played nicely\" together, even if our prior or likelihood wasn't the best choice for our data. It might be harder to summarize our posterior distribution. There might not exist a [closed-form solution](https://en.wikipedia.org/wiki/Closed-form_expression) to our posterior distribution.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>If we can't find a \"closed-form\" solution to our posterior distribution... can we at least approximate one?</summary>\n",
    "\n",
    "- YES!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### MCMC Methods\n",
    "Markov Chain Monte Carlo methods will allow us to approximate the posterior distribution of the parameter of interest. (This is the **why** to what we learned with PyMC!)\n",
    "\n",
    "There are three main components to MCMC Methods.\n",
    "- Monte Carlo Methods\n",
    "- Markov Chains\n",
    "- Acceptance-Rejection Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Monte Carlo Simulations\n",
    "\n",
    "Monte Carlo simulations are a powerful way for us to model complex systems by generating random numbers!\n",
    "\n",
    "For example, we can generate random numbers to estimate the value of $\\pi$!\n",
    "\n",
    "- The area of a circle is given by $\\pi r^2$, where $r$ is the radius (or half-distance) of the circle.\n",
    "- The area of a square is given by $s^2$, where $s$ is the length of one side of the square.\n",
    "\n",
    "<img src=\"./images/circle_square.png\" alt=\"drawing\" width=\"250\"/>\n",
    "\n",
    "- If we place a circle inside a square like above, then the side length of the square $s$ is exactly $2r$.\n",
    "- If we calculate the area of the circle divided by the area of the square, we get:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\text{area of circle}}{\\text{area of square}} &=& \\frac{\\pi r^2}{s^2} \\\\\n",
    "\\\\\n",
    "&=& \\frac{\\pi r^2}{4 r^2} \\\\\n",
    "\\\\\n",
    "&=& \\frac{\\pi}{4}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "How can we find the exact amount of area in the circle and the exact amount of area in the square?\n",
    "- Complicated math.\n",
    "\n",
    "Can we get a good approximation of the area in the circle and the area in the square?\n",
    "- **Yes!** Let's pretend like we're sprinking sand all over the circle and square and can count up how much sand falls inside the circle and how much sand falls inside the square.\n",
    "- Realistically, we can't do this. There's not a way for us to easily count how many grains of sand fall inside the circle... but we can use computers to do this.\n",
    "\n",
    "<img src=\"./images/pi_estimation.gif\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy and Matplotlib.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Spread grains of sand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each grain of sand is inside the circle.\n",
    "\n",
    "# Start counter at 0.\n",
    "\n",
    "\n",
    "# Iterate through each grain of sand.\n",
    "\n",
    "    \n",
    "    # Check to see if each grain of sand is inside the circle.\n",
    "    \n",
    "        \n",
    "        # If so, add one to count.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sand in circle divided by sand in square.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\text{area of circle}}{\\text{area of square}} &=& \\frac{\\pi}{4} \\\\\n",
    "\\Rightarrow \\frac{\\text{sand in circle}}{\\text{sand in square}} &\\approx& \\frac{\\pi}{4} \\\\\n",
    "\\Rightarrow 4 \\times \\frac{\\text{sand in circle}}{\\text{sand in square}} &\\approx& \\pi \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply by four.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our own plots.\n",
    "\n",
    "# Start counter at 0.\n",
    "count = 0\n",
    "\n",
    "# What horizontal axis values are we plotting?\n",
    "horiz = np.linspace(0,1,100)\n",
    "\n",
    "# Iterate through each grain of sand.\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    # Check to see if each grain of sand is inside the circle.\n",
    "    if x[i] ** 2 + y[i] ** 2 <= 1:\n",
    "        \n",
    "        # If so, add one to count.\n",
    "        count += 1\n",
    "    \n",
    "    if (i + 1) in [25, 250, 2_500, 25_000, 250_000]:\n",
    "        # Set figure size.\n",
    "        plt.figure(figsize = (13, 13))\n",
    "\n",
    "        # Plot line of circle: x^2 + y^2 = 1\n",
    "        plt.plot(horiz, # horizontal axis values\n",
    "                 [np.sqrt(1 - x_i ** 2) for x_i in horiz], # height of function values\n",
    "                 lw = 5, # line width = 5\n",
    "                 color = 'k') # change it to black\n",
    "\n",
    "        # Generate scatterplot of points.\n",
    "        plt.scatter(x[:i], # horizontal location of dot\n",
    "                    y[:i], # vertical location of dot\n",
    "                    alpha = 0.4) # transparency of dot (make it 60% transparent, 40% solid)\n",
    "\n",
    "        plt.title(fr'Estimate of $\\pi$ is {round(4 * count / i,6)} with n = {i + 1}.', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Monte Carlo simulations are used to model much more complicated things as well. In calculus, if you remember calculating the integral (area under the curve), you had to remember those nasty \"integration by parts\" formulas and \"u-substitution.\" Monte Carlo simulations make that [relatively trivial with computers](https://www.youtube.com/watch?v=GZXhGwCXct0)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main components to MCMC Methods.\n",
    "- Monte Carlo Methods\n",
    "- Markov Chains\n",
    "- Acceptance-Rejection Sampling\n",
    "\n",
    "### Markov Chains\n",
    "\n",
    "Markov Chains are a way for us to see how a random variable changes from one state to another over time.\n",
    "\n",
    "[Setosa.io](http://setosa.io/blog/2014/07/26/markov-chains/) has a great visualization of Markov chains.\n",
    "\n",
    "There's something called the **Markov property** that we'll rely on when doing MCMC methods.\n",
    "\n",
    "The **Markov property** is the following:\n",
    "\n",
    "$$\n",
    "f(X_{t+1}|X_t) = f(X_{t+1}|X_t, X_{t-1}, X_{t-2}, \\ldots, X_1)\n",
    "$$\n",
    "\n",
    "In words, if I know what is happening at time $t$, then I know just as much about what will happen at $t+1$ as I would know if I knew what happened at time $t$, $t-1$, $t-2$ all the way back to time $1$.\n",
    "\n",
    "Phrased another way, if I know what value my variable takes on at time $t$, knowing what value my variable took on at $t-1$ and so on doesn't provide me with any additional information!\n",
    "\n",
    "#### Markov Chain Examples\n",
    "- Genetics: If I know the genotypes {`AA`, `Aa`, `aa`} of the parents, then that summarizes what I can learn about the children. Knowing the genotypes of grandparents, great-grandparents, etc. doesn't give me any additional information!\n",
    "- Monopoly: Knowing where players currently exist on the board on turn $t$ completely summarizes where players will be on the board in turn $t+1$. Knowing where people were one, two, or more turns ago doesn't give me any additional information!\n",
    "- Baseball: Knowing the current number of outs and the current position of runners completely summarizes what can happen in the next \"at bat.\"\n",
    "- Google's PageRank Algorithm: Google assumes that where you are now on the Internet completely summarizes where you will go next.\n",
    "    \n",
    "    \n",
    "The Markov property is very important to MCMC methods. (Spoiler alert: when we sample random numbers, we're going to rely on the previous random number to help randomly generate the next one!) Additionally, the long-run behavior of Markov chains is very interesting. Let's take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to model the weather. I'll assume that the Markov property applies here, even though that's probably not a very good assumption for us to make.\n",
    "\n",
    "Let $C$ indicate **clear**, $R$ indicate **rainy**, and $S$ indicate **snowy**.\n",
    "\n",
    "- If $X_t=C$, then $P(X_{t+1}=C)=0.6$, $P(X_{t+1}=R)=0.3$, $P(X_{t+1}=S)=0.1$.\n",
    "- If $X_t=R$, then $P(X_{t+1}=C)=0.4$, $P(X_{t+1}=R)=0.4$, $P(X_{t+1}=S)=0.2$.\n",
    "- If $X_t=S$, then $P(X_{t+1}=C)=0.3$, $P(X_{t+1}=R)=0.3$, $P(X_{t+1}=S)=0.4$.\n",
    "\n",
    "We can represent this in a matrix.\n",
    "\n",
    "$$\\begin{equation} \\mathbf{A} = \n",
    "\\left[\\begin{array}{ccc} \n",
    "      0.6 & 0.4 & 0.3\\\\\n",
    "      0.3 & 0.4 & 0.3\\\\\n",
    "      0.1 & 0.2 & 0.4\\\\\n",
    "\\end{array}\\right]\n",
    "\\end{equation}$$\n",
    "\n",
    "The first row and first column represent clear, the second row and column represent rainy, and the third row and column represent snowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of probabilities.\n",
    "transition_matrix = np.array([[0.6, 0.4, 0.3],\n",
    "                              [0.3, 0.4, 0.3],\n",
    "                              [0.1, 0.2, 0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the transition matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find what the weather is like on day two ($\\mathbf{y}_2$), I need to specify the weather on day 1 ($\\mathbf{y}_1$), then multiply $\\mathbf{A}$ by $\\mathbf{y}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weather vector for day 1.\n",
    "y_1 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weather vector for day 2.\n",
    "y_2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find what the weather is like on day three ($\\mathbf{y}_3$), I need to specify the weather on day 2 ($\\mathbf{y}_2$), then multiply $\\mathbf{A}$ by $\\mathbf{y}_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weather vector for day 3.\n",
    "y_3 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually find out the weather on day 3 from just using day 1!\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\mathbf{y}_3 &=& \\mathbf{A}\\mathbf{y}_2 \\\\\n",
    "\\mathbf{y}_3 &=& \\mathbf{A}(\\mathbf{A}\\mathbf{y}_1) \\\\\n",
    "\\mathbf{y}_3 &=& \\mathbf{A}^2\\mathbf{y}_1 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weather vector for day 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if we want to predict 1,000 days from now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function.\n",
    "def long_run(A, num_steps, first_state):\n",
    "    \n",
    "    # Take matrix to num_steps power.\n",
    "    \n",
    "    \n",
    "    # Return weather vector on day A_power * first_state\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 1,000 days from now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What about 10,000?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 10,000 days from now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Markov chains, under pretty weak assumptions, will converge to some long-run behavior. (This is really good for MCMC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happens if it's not snowy on day 1? How does this affect that long-run behavior?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weather vector for day 1.\n",
    "y_1 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 1,000 days from now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Markov chains, under pretty weak assumptions, will converge to some long-run behavior **independent of the starting point!** (This is *exceptionally* good for MCMC.)\n",
    "- These assumptions, called **irreducibility** and **aperiodicity**, will always be satisfied in our MCMC implementation. We won't dive into more than that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Monte Carlo Simulations with Markov Chains\n",
    "\n",
    "Remember that, as always, our goal is to get to the **posterior distribution of the parameter of interest**.\n",
    "\n",
    "In PyMC, we generate a **trace** or **chain** of values from the posterior distribution.\n",
    "\n",
    "Without getting into the third piece (yet), let's look at what we're doing.\n",
    "\n",
    "\n",
    "If we were to just generate random numbers without any rhyme or reason, we'd be doing a Monte Carlo simulation.\n",
    "<img src=\"./images/montecarlo.gif\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "- On the right-hand side, we have all of our samples. In this case, we're sampling from a $N(0.5, \\sigma)$ distribution.\n",
    "- On the left-hand side, we have a frequency histogram of our samples.\n",
    "- Note how the distribution we're sampling from stays the same here. This won't actually be the case in MCMC - we want this distribution to change. (Spoiler alert: we want this distribution to get closer to the posterior distribution!)\n",
    "\n",
    "Suppose that, instead, we're still generating random numbers. However, this time, the last random number we generate influences the next random number we generate.\n",
    "\n",
    "<img src=\"./images/markovchain.gif\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "- Our right-hand side is our trace plot and our left-hand side is the histogram of sampled values from the trace plot.\n",
    "- Note that the distribution we're sampling from is now changing! Specifically, the mean of the distribution we sample from at each step is now the previously sampled observation.\n",
    "    - This is our **Markov property** in action - the step at time $t$ is the only one that influences what happens at time $t+1$!\n",
    "- What we're viewing right now is known as a \"random walk.\" It's our hope that this gets closer to the posterior distribution. We'll need a little extra help to get there, though.\n",
    "- The extra help we need is an acceptance-rejection algorithm to tell us \"are we going in the right direction or the wrong direction?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "There are three main components to MCMC Methods.\n",
    "- Monte Carlo Methods\n",
    "- Markov Chains\n",
    "- Acceptance-Rejection Sampling\n",
    "\n",
    "### Acceptance-Rejection Sampling\n",
    "\n",
    "- Acceptance-rejection sampling is a specific type of Monte Carlo sampling.\n",
    "\n",
    "- We’re going to sample some observation, then decide whether to keep it (accept it) or discard it (reject it). \n",
    "    - Specifically, we will accept these values a certain percentage of the time and reject a certain percentage of the time.\n",
    "\n",
    "- As our random walk moves about, we need some way to make sure that we’re moving in the right direction.\n",
    "    - If we are moving in the right direction, we’ll accept that sample.\n",
    "    - If we aren’t moving in the right direction, we may reject that sample.\n",
    "\n",
    "We’ll walk through a specific algorithm to accept/reject, called the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm).\n",
    "- PyMC by default will implement a more sophisticated algorithm called the [No U-Turn Sampler](https://arxiv.org/abs/1111.4246).\n",
    "\n",
    "The Metropolis-Hastings algorithm allows us to, at each step, identify whether we are getting “hotter” or “colder.”\n",
    "\n",
    "#### Metropolis-Hastings Algorithm\n",
    "Part 1. Generate $\\theta_{proposal} \\sim N(\\theta_{t-1}, \\sigma)$.\n",
    "\n",
    "Part 2. Calculate the ratio of posterior probabilities $r = \\frac{P(\\theta_{proposal}|y)}{P(\\theta_{t-1}|y)}$.\n",
    "- Since we have specified the prior and the likelihood, we can just find the posterior probability of these specific values!\n",
    "- If $r \\ge 1$, then $\\theta_{proposal}$ is a likelier value for our posterior distribution than $\\theta_{t-1}$. You can think of this as \"we're heading in the right direction.\"\n",
    "- If $r < 1$, then $\\theta_{proposal}$ is not a likelier value for our posterior distribution than $\\theta_{t-1}$. You can think of this as \"we're heading in a direction of lower probability.\"\n",
    "\n",
    "Part 3. Calculate our acceptance probability $\\alpha = \\min\\{r,1\\}$.\n",
    "- This is the probability that we'll accept $\\theta_{proposal}$ as our new value $\\theta_t$.\n",
    "- If $r \\ge 1$, then $\\theta_{proposal}$ is a likelier value for our posterior distribution than $\\theta_{t-1}$ and our acceptance probability is 100%!\n",
    "- If $r < 1$, then $\\theta_{proposal}$ is not a likelier value for our posterior distribution than $\\theta_{t-1}$, so we may reject $\\theta_{proposal}$.\n",
    "\n",
    "Part 4. We want to get our computer to basically flip a coin with probability of success $\\alpha$ to determine whether or not we accept $\\theta_{proposal}$. We generate $U_t \\sim Uniform(0,1)$.\n",
    "- If $U_t \\le \\alpha$, then accept $\\theta_{proposal}$. (That is, $\\theta_t = \\theta_{proposal}$.)\n",
    "- If $U_t > \\alpha$, then reject $\\theta_{proposal}$. (That is, $\\theta_t = \\theta_{t-1}$.)\n",
    "\n",
    "Remember that we've already seen how Markov chains and Monte Carlo simulations can work together. Let's add the acceptance/rejection component to this!\n",
    "\n",
    "<img src=\"./images/acceptancerejection.gif\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "We will repeat this process a large number of times - the number of samples we generate with `pm.sample()`.\n",
    "\n",
    "Once we do this long enough and visually inspect traceplots to convince ourselves that we have “converged” to the posterior distribution of interest, we usually discard early samples (before we converged), then we store some large $n$ of the later samples.\n",
    "- We might run this multiple times (by setting `chains` > 1 in `PyMC`) to protect against converging to a local optimum.\n",
    "\n",
    "Once we have our sample of size $n$, we can conduct whatever inference we want on the posterior distribution of the parameter of interest.\n",
    "- Find the mean.\n",
    "- Find the median.\n",
    "- Find the 95% ‘highest posterior density.’\n",
    "- Find the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's head to [a website](https://chi-feng.github.io/mcmc-demo/app.html#RandomWalkMH,standard) to see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Our goal is to always find the posterior distribution. Why would we want that?</summary>\n",
    "\n",
    "- The posterior distribution is a complete summary of $\\theta$ after taking our data/evidence into account.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>When is MCMC helpful?</summary>\n",
    "\n",
    "- It's helpful in cases when we don't have conjugate priors/posteriors... or if we just don't want to do the math!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How does MCMC work?</summary>\n",
    "\n",
    "- MCMC is a method that can find the posterior distribution of our parameter of interest. Specifically, this type of algorithm generates Monte Carlo simulations in a way that relies on the Markov property, then accepts these simulations at a certain rate to get the posterior distribution.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNING OBJECTIVES\n",
    "By the end of this lesson, students should be able to:\n",
    "- Identify the Markov property.\n",
    "- Describe Monte Carlo simulations.\n",
    "- Describe how MCMC works.\n",
    "- Identify situations where MCMC is beneficial.\n",
    "\n",
    "---\n",
    "\n",
    "### Framing: What should you get out of this lecture?\n",
    "- Markov Chains and Monte Carlo methods (separately) are important tools in many settings. These are terms with which you want to be familiar, as this won't be the last time that you see them.\n",
    "- When asked about MCMC, there are three answers you can give.\n",
    "    - **Basic**: MCMC allows us to leverage computers to do Bayesian statistics.\n",
    "    - **Intermediate**: MCMC is a method that can find the posterior distribution of our parameter of interest. Specifically, this type of algorithm generates Monte Carlo simulations in a way that relies on the Markov property, then accepts these simulations at a certain rate to get the posterior distribution.\n",
    "    - **Advanced**: The full-blown lecture.\n",
    "    \n",
    "Our goal was to get you to that intermediate stage today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
