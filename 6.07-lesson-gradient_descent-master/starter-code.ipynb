{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Code-Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through how gradient descent works using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate data from a Poisson(45) distribution.\n",
    "temp ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View array.\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and sample variance of array.\n",
    "print(np.mean(temp))\n",
    "print(np.var(temp, ddof = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ohio State Fun Facts:**\n",
    "1. Ohio Stadium can seat 102,082 people. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Ohio_Stadium).)\n",
    "2. Ohio Stadium's record attendance is 110,045 people. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Ohio_Stadium).)\n",
    "3. Ohio State is better than Michigan. (Source: It's just a fact.)\n",
    "4. Ohio State students enjoy soda. (Source: first-hand knowledge.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sodas ~ N(200000 + 1000 * temp, 20000)\n",
    "sodas_sold ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sodas_sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{sodas_sold}_i = 200000 + 1000 * \\text{temp}_i + \\varepsilon_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with temp and sodas_sold.\n",
    "df ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first five rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal is to fit a model here.\n",
    "- You and I know that our $y$-intercept $\\beta_0$ is 200,000.\n",
    "- You and I know that our slope $\\beta_1$ is 1,000.\n",
    "- However, our computer does not know that. Our computer has to estimate $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ from the data.\n",
    "    - We might say that our **machine** has to... **learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our workflow:\n",
    "1. Instantiate model.\n",
    "2. Select a learning rate $\\alpha$.\n",
    "3. Select a starting point $\\hat{\\beta}_{1,0}$.\n",
    "4. Calculate the gradient of the loss function.\n",
    "5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$.\n",
    "6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$.\n",
    "7. Repeat steps 4 through 6 until \"stopping condition\" is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Instantiate model.\n",
    "\n",
    "Our model takes on the form:\n",
    "$$ Y = \\beta_0 + \\beta_1 X + \\varepsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Select a learning rate $\\alpha$.\n",
    "\n",
    "$$\\alpha = 0.1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Select a starting point.\n",
    "The zero-th iteration of $\\hat{\\beta}_1$ is going to start at, say, 20.\n",
    "$$\\hat{\\beta}_{1,0} = 20$$\n",
    "\n",
    "Two points:\n",
    "- You and I know that the true value of $\\beta_1$ is 1000. We need the computer to figure (machine to learn) that part out!\n",
    "- We're going to pretend like the computer already knows the value for $\\beta_0$. In reality, we'd have to do this for $\\beta_0$ and for $\\beta_1$ at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Calculate the gradient of the loss function with respect to parameter $\\beta_1$.\n",
    "\n",
    "The loss function, $L$, is our mean square error.\n",
    "\n",
    "$$L = \\frac{1}{n}\\sum_{i = 1} ^ n (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "$$\\Rightarrow L = \\frac{1}{n}\\sum_{i = 1} ^ n \\left(y_i - \\left(\\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\right)\\right)^2 $$\n",
    "\n",
    "The gradient of this loss function with respect to $\\beta_1$ is:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\beta_1} = \\frac{2}{n} \\sum_{i=1}^n -x_i\\left(y_i - \\left(\\hat{\\beta}_1x_i + \\hat{\\beta}_0\\right)\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gradient of beta_1.\n",
    "def beta_1_gradient(x, y, beta_1, beta_0):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate new value of beta_1.\n",
    "def update_beta_1(beta_1, alpha, gradient):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_update(beta_1, updated_beta_1, tolerance = 0.1):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Save final value of $\\hat{\\beta}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, beta_1 = 0, alpha = 0.01, max_iter = 100):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call gradient_descent with an initial beta_1 of 20, alpha of 0.01, and 100 iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What should we do?</summary>\n",
    "\n",
    "- We **should not** adjust our maximum iterations. It doesn't look like we'll converge.\n",
    "- We should adjust our alpha!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
