{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice Building a Production Model\n",
    "Author:  Dave Yerrington (SF)\n",
    "\n",
    "Integrate an endpoint called \"predict-iris\" that will use a classification method of your choice.  Build a model in Jupyter, then load it into Flask and use it!\n",
    "\n",
    "1. Build a response that will react to these parameters:\n",
    "- sepal_len and sepal_width\n",
    "- Have the response return a message that includes class predictions and probabilities (if the model provides)\n",
    "- Have the response return a message to inform your users to set the correct parameters if they are not set\n",
    "\n",
    "2. Extend your model to include the additional 2 parameters to predict on\n",
    "3. Extend your service to accept multiple predictions at once\n",
    "> Check this out for handling multiple input items:\n",
    ">\n",
    "> http://stackoverflow.com/questions/14188451/get-multiple-request-params-of-the-same-name\n",
    "\n",
    "**BONUS**\n",
    "\n",
    "Implement cross-validation in your notebook model and additionally return the recall, precision, and plot a ROC curve.  Save your classification metric results as a new object (for instance a dictionary), serialize using joblib, then load them as part of your response in your Flask service for the iris prediction.\n",
    "\n",
    "\n",
    "See these details:\n",
    "http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "http://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "\n",
    "Here is some reference / starter code to get you going with the dataset:\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data['data'], columns=['sepal_len', 'sepal_width', 'petal_lengh', 'petal_width'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Serialization\n",
    "\n",
    "After you've fit your `model` object, you can use joblib to save your model from this notebook, which will create a pickle file.  Then copy your `.pkl` file to your Flask service directory, then load it from there to finish your integration.  Check the suggested reading above for further details.\n",
    "\n",
    "**After loading your file into Flask**\n",
    "\n",
    "Once you load your model back into Flask, it will behave just like any other sklearn model object. It will have a `.predict()` method that you can use to finish your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(model, 'my_model.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
