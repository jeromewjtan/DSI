{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![GA Logo](https://camo.githubusercontent.com/6ce15b81c1f06d716d753a61f5db22375fa684da/68747470733a2f2f67612d646173682e73332e616d617a6f6e6177732e636f6d2f70726f64756374696f6e2f6173736574732f6c6f676f2d39663838616536633963333837313639306533333238306663663535376633332e706e67) Naive Bayes\n",
    "\n",
    "We've looked at the Naive Bayes classifier from a probability point of view. Now let's apply code to it to a natural language processing problem.\n",
    "\n",
    "### Before we begin... what is natural language processing?\n",
    "\n",
    "- If I'm explaining this to my non-technical peers, natural language processing is just a way for us to get computers to understand written language the way you and I do.\n",
    "\n",
    "- If I'm explaining this to someone with a more technical background, natural language processing is a set of tools that represent words as numbers. This is commonly done by feature engineering (i.e. turning words into columns in your dataframe), but more complicated methods exist.\n",
    "\n",
    "You'll often see natural language processing abbreviated as **NLP**.\n",
    "\n",
    "You and I will use these social media posts in a Naive Bayes classification model to predict whether a post comes from Twitter or Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First: some data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the .csv file.\n",
    "\n",
    "df = pd.read_csv(\"unprocessed_tweets.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
       "       '_last_judgment_at', 'audience', 'audience:confidence', 'bias',\n",
       "       'bias:confidence', 'message', 'message:confidence', 'orig__golden',\n",
       "       'audience_gold', 'bias_gold', 'bioid', 'embed', 'id', 'label',\n",
       "       'message_gold', 'source', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the columns.\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>audience</th>\n",
       "      <th>audience:confidence</th>\n",
       "      <th>bias</th>\n",
       "      <th>bias:confidence</th>\n",
       "      <th>message</th>\n",
       "      <th>...</th>\n",
       "      <th>orig__golden</th>\n",
       "      <th>audience_gold</th>\n",
       "      <th>bias_gold</th>\n",
       "      <th>bioid</th>\n",
       "      <th>embed</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>message_gold</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>766192484</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:17</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R000596</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.83249E+17</td>\n",
       "      <td>From: Trey Radel (Representative from Florida)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>766192485</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:20</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>attack</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M000355</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.11208E+17</td>\n",
       "      <td>From: Mitch McConnell (Senator from Kentucky)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>766192486</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:14</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>support</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S001180</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>3.39069E+17</td>\n",
       "      <td>From: Kurt Schrader (Representative from Oregon)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>766192487</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:08</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C000880</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>2.98528E+17</td>\n",
       "      <td>From: Michael Crapo (Senator from Idaho)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>766192488</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>1</td>\n",
       "      <td>8/4/15 21:26</td>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "      <td>partisan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U000038</td>\n",
       "      <td>&lt;blockquote class=\"twitter-tweet\" width=\"450\"&gt;...</td>\n",
       "      <td>4.07643E+17</td>\n",
       "      <td>From: Mark Udall (Senator from Colorado)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  766192484    False   finalized                   1      8/4/15 21:17   \n",
       "1  766192485    False   finalized                   1      8/4/15 21:20   \n",
       "2  766192486    False   finalized                   1      8/4/15 21:14   \n",
       "3  766192487    False   finalized                   1      8/4/15 21:08   \n",
       "4  766192488    False   finalized                   1      8/4/15 21:26   \n",
       "\n",
       "   audience  audience:confidence      bias  bias:confidence  message  ...  \\\n",
       "0  national                  1.0  partisan              1.0   policy  ...   \n",
       "1  national                  1.0  partisan              1.0   attack  ...   \n",
       "2  national                  1.0   neutral              1.0  support  ...   \n",
       "3  national                  1.0   neutral              1.0   policy  ...   \n",
       "4  national                  1.0  partisan              1.0   policy  ...   \n",
       "\n",
       "   orig__golden  audience_gold  bias_gold    bioid  \\\n",
       "0           NaN            NaN        NaN  R000596   \n",
       "1           NaN            NaN        NaN  M000355   \n",
       "2           NaN            NaN        NaN  S001180   \n",
       "3           NaN            NaN        NaN  C000880   \n",
       "4           NaN            NaN        NaN  U000038   \n",
       "\n",
       "                                               embed           id  \\\n",
       "0  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.83249E+17   \n",
       "1  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.11208E+17   \n",
       "2  <blockquote class=\"twitter-tweet\" width=\"450\">...  3.39069E+17   \n",
       "3  <blockquote class=\"twitter-tweet\" width=\"450\">...  2.98528E+17   \n",
       "4  <blockquote class=\"twitter-tweet\" width=\"450\">...  4.07643E+17   \n",
       "\n",
       "                                              label message_gold   source  \\\n",
       "0    From: Trey Radel (Representative from Florida)          NaN  twitter   \n",
       "1     From: Mitch McConnell (Senator from Kentucky)          NaN  twitter   \n",
       "2  From: Kurt Schrader (Representative from Oregon)          NaN  twitter   \n",
       "3          From: Michael Crapo (Senator from Idaho)          NaN  twitter   \n",
       "4          From: Mark Udall (Senator from Colorado)          NaN  twitter   \n",
       "\n",
       "                                                text  \n",
       "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...  \n",
       "1  VIDEO - #Obamacare:  Full of Higher Costs and ...  \n",
       "2  Please join me today in remembering our fallen...  \n",
       "3  RT @SenatorLeahy: 1st step toward Senate debat...  \n",
       "4  .@amazon delivery #drones show need to update ...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first five rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                  0\n",
       "_golden                   0\n",
       "_unit_state               0\n",
       "_trusted_judgments        0\n",
       "_last_judgment_at         0\n",
       "audience                  0\n",
       "audience:confidence       0\n",
       "bias                      0\n",
       "bias:confidence           0\n",
       "message                   0\n",
       "message:confidence        0\n",
       "orig__golden           5000\n",
       "audience_gold          5000\n",
       "bias_gold              5000\n",
       "bioid                     0\n",
       "embed                     0\n",
       "id                        0\n",
       "label                     0\n",
       "message_gold           5000\n",
       "source                    0\n",
       "text                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all values with an \"audience confidence,\" \"bias\n",
    "# confidence,\" or \"message confidence\" score below 1.\n",
    "\n",
    "df = df[(df[\"audience:confidence\"]>=1) & (df[\"bias:confidence\"]>=1) & (df[\"message:confidence\"]>=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra columns.\n",
    "\n",
    "df = df[['_unit_id', '_trusted_judgments', 'audience',\n",
    "         'bias', 'message', 'label', 'source', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel columns.\n",
    "\n",
    "df.columns = ['unit_id', 'trusted_judgments', 'audience_feature',\n",
    "              'bias_feature', 'message_feature', 'label_feature',\n",
    "              'source_feature', 'text_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index.\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have social media data! This includes almost 5,000 messages on either Twitter or Facebook from various politicians. We can use the features we generated to predict things like whether the source is Twitter or Facebook, whether the bias is neutral or partisan, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows and columns do we have?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>trusted_judgments</th>\n",
       "      <th>audience_feature</th>\n",
       "      <th>bias_feature</th>\n",
       "      <th>message_feature</th>\n",
       "      <th>label_feature</th>\n",
       "      <th>source_feature</th>\n",
       "      <th>text_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>766192484</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Trey Radel (Representative from Florida)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>766192485</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>attack</td>\n",
       "      <td>From: Mitch McConnell (Senator from Kentucky)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>766192486</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "      <td>support</td>\n",
       "      <td>From: Kurt Schrader (Representative from Oregon)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>766192487</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>neutral</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Michael Crapo (Senator from Idaho)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>766192488</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>partisan</td>\n",
       "      <td>policy</td>\n",
       "      <td>From: Mark Udall (Senator from Colorado)</td>\n",
       "      <td>twitter</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_id  trusted_judgments audience_feature bias_feature message_feature  \\\n",
       "0  766192484                  1         national     partisan          policy   \n",
       "1  766192485                  1         national     partisan          attack   \n",
       "2  766192486                  1         national      neutral         support   \n",
       "3  766192487                  1         national      neutral          policy   \n",
       "4  766192488                  1         national     partisan          policy   \n",
       "\n",
       "                                      label_feature source_feature  \\\n",
       "0    From: Trey Radel (Representative from Florida)        twitter   \n",
       "1     From: Mitch McConnell (Senator from Kentucky)        twitter   \n",
       "2  From: Kurt Schrader (Representative from Oregon)        twitter   \n",
       "3          From: Michael Crapo (Senator from Idaho)        twitter   \n",
       "4          From: Mark Udall (Senator from Colorado)        twitter   \n",
       "\n",
       "                                        text_feature  \n",
       "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...  \n",
       "1  VIDEO - #Obamacare:  Full of Higher Costs and ...  \n",
       "2  Please join me today in remembering our fallen...  \n",
       "3  RT @SenatorLeahy: 1st step toward Senate debat...  \n",
       "4  .@amazon delivery #drones show need to update ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first five rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may note that there are some extra symbols in the data. This is a common problem in natural language processing, especially when dealing with social media (think emoji, hashtags, links, etc.), but we're going to ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use Naive Bayes to predict whether a social media post was featured on Facebook or Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Engineer a feature to turn `source_feature` into a 1/0 column, where 1 indicates `Twitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['twitter', 'facebook'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source_feature.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitter'] = df.source_feature.map({'facebook':0, 'twitter':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2497\n",
       "1    2391\n",
       "Name: twitter, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.twitter.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Since we are solving a classification problem, what potential issue should I check for here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split our data into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text_feature']]\n",
    "y = df['twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_feature\n",
       "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...\n",
       "1  VIDEO - #Obamacare:  Full of Higher Costs and ...\n",
       "2  Please join me today in remembering our fallen...\n",
       "3  RT @SenatorLeahy: 1st step toward Senate debat...\n",
       "4  .@amazon delivery #drones show need to update ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split our data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Turn our text into features. [Documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#cvec = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Instantiate our CountVectorizer.\n",
    "max_words = 25\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "tvec = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2981    Tennessee is certainly leading the country in ...\n",
       "1092    Tim Howard, @USSoccer played a strong half.  N...\n",
       "1082    Proud to stand with @Daddies &amp; all Oregon ...\n",
       "4876    More great news for IU:  The Peace Corps has r...\n",
       "3463    Happy 70th birthday to the USS  Iowa! We are s...\n",
       "Name: text_feature, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['text_feature'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec = cvec.fit_transform(X_train['text_feature'])\n",
    "X_train_tvec = tvec.fit_transform(X_train['text_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14848"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14848"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3666x14848 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 65299 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec_df = pd.DataFrame(X_train_cvec.toarray(), columns=cvec.get_feature_names())\n",
    "X_train_tvec_df = pd.DataFrame(X_train_tvec.toarray(), columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0017a43b2370</th>\n",
       "      <th>00am</th>\n",
       "      <th>00amct</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010914</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>Ã»Ã³that</th>\n",
       "      <th>Ã»Ã³the</th>\n",
       "      <th>Ã»Ã³this</th>\n",
       "      <th>Ã»Ã³today</th>\n",
       "      <th>Ã»Ã³unifying</th>\n",
       "      <th>Ã»Ã³urgent</th>\n",
       "      <th>Ã»Ã³wanting</th>\n",
       "      <th>Ã»Ã³we</th>\n",
       "      <th>Ã»Ã³while</th>\n",
       "      <th>Ã»Ã³women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000th  0017a43b2370  00am  00amct  00pm  01  010914  02  ...  \\\n",
       "0   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "2   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "3   0    0      0             0     0       0     0   0       0   1  ...   \n",
       "4   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "\n",
       "   Ã»Ã³that  Ã»Ã³the  Ã»Ã³this  Ã»Ã³today  Ã»Ã³unifying  Ã»Ã³urgent  Ã»Ã³wanting  Ã»Ã³we  \\\n",
       "0       0      0       0        0           0         0          0     0   \n",
       "1       0      0       0        0           0         0          0     0   \n",
       "2       0      0       0        0           0         0          0     0   \n",
       "3       0      0       0        0           0         0          0     0   \n",
       "4       0      0       0        0           0         0          0     0   \n",
       "\n",
       "   Ã»Ã³while  Ã»Ã³women  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        0  \n",
       "4        0        0  \n",
       "\n",
       "[5 rows x 14848 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = cvec.transform(X_test['text_feature']).todense()\n",
    "X_test_tvec = tvec.transform(X_test['text_feature']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cvec_df = pd.DataFrame(X_test_cvec, columns=cvec.get_feature_names())\n",
    "X_test_tvec_df = pd.DataFrame(X_test_tvec, columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>0017a43b2370</th>\n",
       "      <th>00am</th>\n",
       "      <th>00amct</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>010914</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>Ã»Ã³that</th>\n",
       "      <th>Ã»Ã³the</th>\n",
       "      <th>Ã»Ã³this</th>\n",
       "      <th>Ã»Ã³today</th>\n",
       "      <th>Ã»Ã³unifying</th>\n",
       "      <th>Ã»Ã³urgent</th>\n",
       "      <th>Ã»Ã³wanting</th>\n",
       "      <th>Ã»Ã³we</th>\n",
       "      <th>Ã»Ã³while</th>\n",
       "      <th>Ã»Ã³women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1222 rows Ã— 14848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000th  0017a43b2370  00am  00amct  00pm  01  010914  02  ...  \\\n",
       "0      0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1      0    0      0             0     0       0     0   0       0   0  ...   \n",
       "2      0    0      0             0     0       0     0   0       0   0  ...   \n",
       "3      0    0      0             0     0       0     0   0       0   0  ...   \n",
       "4      0    0      0             0     0       0     0   0       0   0  ...   \n",
       "...   ..  ...    ...           ...   ...     ...   ...  ..     ...  ..  ...   \n",
       "1217   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1218   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1219   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1220   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "1221   0    0      0             0     0       0     0   0       0   0  ...   \n",
       "\n",
       "      Ã»Ã³that  Ã»Ã³the  Ã»Ã³this  Ã»Ã³today  Ã»Ã³unifying  Ã»Ã³urgent  Ã»Ã³wanting  Ã»Ã³we  \\\n",
       "0          0      0       0        0           0         0          0     0   \n",
       "1          0      0       0        0           0         0          0     0   \n",
       "2          0      0       0        0           0         0          0     0   \n",
       "3          0      0       0        0           0         0          0     0   \n",
       "4          0      0       0        0           0         0          0     0   \n",
       "...      ...    ...     ...      ...         ...       ...        ...   ...   \n",
       "1217       0      0       0        0           0         0          0     0   \n",
       "1218       0      0       0        0           0         0          0     0   \n",
       "1219       0      0       0        0           0         0          0     0   \n",
       "1220       0      0       0        0           0         0          0     0   \n",
       "1221       0      0       0        0           0         0          0     0   \n",
       "\n",
       "      Ã»Ã³while  Ã»Ã³women  \n",
       "0           0        0  \n",
       "1           0        0  \n",
       "2           0        0  \n",
       "3           0        0  \n",
       "4           0        0  \n",
       "...       ...      ...  \n",
       "1217        0        0  \n",
       "1218        0        0  \n",
       "1219        0        0  \n",
       "1220        0        0  \n",
       "1221        0        0  \n",
       "\n",
       "[1222 rows x 14848 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cvec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit a Naive Bayes model!\n",
    "\n",
    "<details><summary> Which Naive Bayes model should we pick, and why? </summary>\n",
    "    \n",
    "- The columns of X are all integer counts, so MultinomialNB is the best choice here.\n",
    "- BernoulliNB is best when we have 0/1 counts in all columns of X. (a.k.a. dummy variables)\n",
    "- GaussianNB is best when the columns of X are Normally distributed. (Practically, though, it gets used whenever BernoulliNB and MultinomialNB are inappropriate.)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our model!\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model!\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember earlier that I said we had the opportunity to set priors. We could do so here if we wanted, but we'll stick with the default and allow `sklearn` to estimate priors from the training data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model!\n",
    "\n",
    "model = nb.fit(X_train_cvec, y_train)\n",
    "model_tvec = nb.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our predictions!\n",
    "\n",
    "predictions = model.predict(X_test_cvec)\n",
    "pred_tvec = model_tvec.predict(X_test_tvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> How might we evaluate our model's performance? </summary>\n",
    "\n",
    "- Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "- Sensitivity = TP / (TP + FN)\n",
    "- Specificity = TN / (TN + FP)\n",
    "- Precision = TP / (TP + FP)\n",
    "- AUC ROC\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> If we have to select only one, which one should we choose? </summary>\n",
    "\n",
    "- It depends on how exactly you define \"positive\" and \"negative.\" In this case, it probably doesn't really matter - incorrectly mistaking a tweet for a Facebook post doesn't seem much better or worse than incorrectly mistaking a Facebook post for a tweet. \n",
    "- Because I believe false positives and false negatives are equally as bad, I'd probably use accuracy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165302782324058\n",
      "0.9288052373158756\n"
     ]
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "\n",
    "print(model.score(X_train_cvec, y_train))\n",
    "print(model_tvec.score(X_train_tvec, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7471358428805237\n",
      "0.6955810147299509\n"
     ]
    }
   ],
   "source": [
    "# Score our model on the testing set.\n",
    "\n",
    "print(model.score(X_test_cvec, y_test))\n",
    "print(model_tvec.score(X_test_tvec, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> What should we do in this case? </summary>\n",
    "\n",
    "- Our model appears *slightly* overfit. We could:\n",
    "    - try to collect more data, \n",
    "    - try using fewer features by setting `max_features` to a smaller number when instantiating our CountVectorizer,\n",
    "    - try TF-IDF Vectorizer,\n",
    "    - try a non-default prior **if you have subject-matter expertise**.\n",
    "- Rather than regularizing, [online answers](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) suggest using a different model entirely.\n",
    "- Our training performance and testing performance are pretty close, though, so there may not be a lot of changes required.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion matrix function.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[429, 195],\n",
       "       [101, 497]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix.\n",
    "\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 429\n",
      "False Positives: 195\n",
      "False Negatives: 101\n",
      "True Positives: 497\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> By default, what does a true negative mean here? </summary>\n",
    "\n",
    "- True negatives are things we correctly predict to be negative.\n",
    "- In this case, since Twitter = 1, a true negative means I correctly predict something is a Facebook post.\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary> By default, what does a false positive mean here? </summary>\n",
    "\n",
    "- False positives are things we falsely predict to be positive.\n",
    "- In this case, since Twitter = 1, a false positive means I incorrectly preidct something is a tweet (when it's really a Facebook post).\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
